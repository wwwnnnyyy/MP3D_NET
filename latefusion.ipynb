{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60d0a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name:weinanyu\n",
    "# date:20220722\n",
    "#  mag,gra,well\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "def loaddata_func(path1,path2,path4,path5,path3,number):\n",
    "\n",
    "    M_ori = np.load(path2)\n",
    "    G_ori = np.load(path1)\n",
    "    EM_ori = np.load(path4)\n",
    "    WELL_ori = np.load(path5)\n",
    "    Y_ori = np.load(path3)\n",
    "    M_ori = M_ori[:200,:,:,:]\n",
    "    G_ori = G_ori[:200,:,:,:]\n",
    "    EM_ori = EM_ori[:200,:,:,:]\n",
    "    WELL_ori = WELL_ori[:200,:,:]\n",
    "    Y_ori = Y_ori[:200,:,:,:]\n",
    "\n",
    "    train_M=M_ori.reshape([number,-1])\n",
    "    train_M = train_M.reshape([number,1,10,10])\n",
    "    train_G=G_ori.reshape([number,-1])\n",
    "    train_G = train_G.reshape([number,1,20,20])\n",
    "    train_EM=EM_ori.reshape([number,-1])\n",
    "    train_EM = train_EM.reshape([number,2,10,5,8])\n",
    "\n",
    "\n",
    "    train_WELL=WELL_ori.reshape([number,-1])\n",
    "    train_WELL = train_WELL.reshape([number,2,20])\n",
    "\n",
    "    train_Y=Y_ori.reshape([number,-1])\n",
    "    train_Y = train_Y.reshape([number,8000])\n",
    "\n",
    "\n",
    "    train_M=train_M.astype(np.float32)\n",
    "    train_G=train_G.astype(np.float32)\n",
    "    train_EM=train_EM.astype(np.float32)\n",
    "    train_WELL=train_WELL.astype(np.float32)\n",
    "    train_Y=train_Y.astype(np.float32)\n",
    "    M = torch.from_numpy(train_M)\n",
    "    G = torch.from_numpy(train_G)\n",
    "    EM = torch.from_numpy(train_EM)\n",
    "    WELL = torch.from_numpy(train_WELL)\n",
    "    Y=torch.from_numpy(train_Y)\n",
    "    \n",
    "    # dataset_all=TensorDataset(M,G,EM,WELL,Y )\n",
    "\n",
    "    # dataset_all=TensorDataset(M,G,EM,WELL,Y)\n",
    "    dataset_all=TensorDataset(M,G,EM,WELL,Y)\n",
    "    return dataset_all\n",
    "def test_func(path1,path2,path4,path5,path3,number):\n",
    "\n",
    "    M_ori = np.load(path2)\n",
    "    G_ori = np.load(path1)\n",
    "    EM_ori = np.load(path4)\n",
    "    WELL_ori = np.load(path5)\n",
    "    Y_ori = np.load(path3)\n",
    "    M_ori = M_ori[:,:,:,:]\n",
    "    G_ori = G_ori[:,:,:,:]\n",
    "    EM_ori = EM_ori[:,:,:,:]\n",
    "    WELL_ori = WELL_ori[:,:,:]\n",
    "    Y_ori = Y_ori[:,:,:,:]\n",
    "\n",
    "    train_M=M_ori.reshape([number,-1])\n",
    "    train_M = train_M.reshape([number,1,10,10])\n",
    "    train_G=G_ori.reshape([number,-1])\n",
    "    train_G = train_G.reshape([number,1,20,20])\n",
    "    train_EM=EM_ori.reshape([number,-1])\n",
    "    train_EM = train_EM.reshape([number,2,10,5,8])\n",
    "\n",
    "\n",
    "    train_WELL=WELL_ori.reshape([number,-1])\n",
    "    train_WELL = train_WELL.reshape([number,2,20])\n",
    "\n",
    "    train_Y=Y_ori.reshape([number,-1])\n",
    "    train_Y = train_Y.reshape([number,8000])\n",
    "\n",
    "\n",
    "    train_M=train_M.astype(np.float32)\n",
    "    train_G=train_G.astype(np.float32)\n",
    "    train_EM=train_EM.astype(np.float32)\n",
    "    train_WELL=train_WELL.astype(np.float32)\n",
    "    train_Y=train_Y.astype(np.float32)\n",
    "    M = torch.from_numpy(train_M)\n",
    "    G = torch.from_numpy(train_G)\n",
    "    EM = torch.from_numpy(train_EM)\n",
    "    WELL = torch.from_numpy(train_WELL)\n",
    "    Y=torch.from_numpy(train_Y)\n",
    "    \n",
    "    # dataset_all=TensorDataset(M,G,EM,WELL,Y )\n",
    "\n",
    "    # dataset_all=TensorDataset(M,G,EM,WELL,Y)\n",
    "    dataset_all=TensorDataset(M,G,EM,WELL,Y)\n",
    "    return dataset_all\n",
    "\n",
    "def loaddata_func1(path1,path3,number):\n",
    "\n",
    "    # M_ori = np.load(path2)\n",
    "    G_ori = np.load(path1)\n",
    "    Y_ori = np.load(path3)\n",
    "    G_ori = G_ori[:1000,:,:,:]\n",
    "    Y_ori = Y_ori[:1000,:,:,:]\n",
    "\n",
    "    # train_M=M_ori.reshape([number,-1])\n",
    "    # train_M = train_M.reshape([number,1,10,10])\n",
    "    \n",
    "    train_G=G_ori.reshape([number,-1])\n",
    "    train_G = train_G.reshape([number,2,10,10])\n",
    "    train_Y=Y_ori.reshape([number,-1])\n",
    "    train_Y = train_Y.reshape([number,20,20,20])\n",
    "    # train_M=train_M.astype(np.float32)\n",
    "    train_G=train_G.astype(np.float32)\n",
    "    train_Y=train_Y.astype(np.float32)\n",
    "    # M = torch.from_numpy(train_M)\n",
    "    G = torch.from_numpy(train_G)\n",
    "    Y=torch.from_numpy(train_Y)\n",
    "    \n",
    "    dataset_all=TensorDataset(G,Y )\n",
    "    # print(dataset_all.shape)\n",
    "    return dataset_all\n",
    "\n",
    "def shuffle_func(dataset,shuffle_ratio = 0.8):\n",
    "    train_set_size = int(len(dataset) * shuffle_ratio)\n",
    "    valid_set_size = len(dataset) - train_set_size\n",
    "    train_set, valid_set = torch.utils.data.random_split(dataset, [train_set_size, valid_set_size])\n",
    "    return train_set,valid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e203edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv0(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=2, padding=2),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=2, padding=2),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down0(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.2),\n",
    "            DoubleConv0(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up0(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=1, padding=1)\n",
    "\n",
    "        self.conv = DoubleConv0(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv0(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv0, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels , kernel_size=3)\n",
    "        \n",
    "        # self.fc1 = nn.Linear(19200, 16000)\n",
    "    def forward(self, x):\n",
    "        # input_size = x.size(0)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\"\"\"Refer https://github.com/milesial/Pytorch-UNet/blob/master/unet/unet_model.py\"\"\"\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet0(nn.Module):\n",
    "    def __init__(self, n_channels = 1, n_classes = 20, bilinear=False):\n",
    "        super(UNet0, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv0(n_channels, 64)\n",
    "        self.down1 = Down0(64, 128)\n",
    "        self.down2 = Down0(128, 256)\n",
    "        self.down3 = Down0(256, 512)\n",
    "        self.down4 = Down0(512, 512)\n",
    "        self.up1 = Up0(1024, 256, bilinear)\n",
    "        self.up2 = Up0(512, 128, bilinear)\n",
    "        self.up3 = Up0(256, 64, bilinear)\n",
    "        self.up4 = Up0(128, 64, bilinear)\n",
    "        self.outc = OutConv0(64, 20)\n",
    "#         self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        out = logits.view(logits.size(0),-1)\n",
    "#         out = self.relu(logits)\n",
    "#         out = self.sigmoid(logits)\n",
    "        # result = torch.as_tensor((out - 0.5) > 0, dtype=torch.int64) \n",
    "        return out\n",
    "    \n",
    "class DoubleConv1(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=2),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv1(x)\n",
    "\n",
    "\n",
    "class Down1(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.2),\n",
    "            DoubleConv1(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up1(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.conv = DoubleConv1(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv1, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels , kernel_size=5)\n",
    "        \n",
    "        # self.fc1 = nn.Linear(19200, 16000)\n",
    "    def forward(self, x):\n",
    "        # input_size = x.size(0)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\"\"\"Refer https://github.com/milesial/Pytorch-UNet/blob/master/unet/unet_model.py\"\"\"\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet1(nn.Module):\n",
    "    def __init__(self, n_channels = 1, n_classes = 20, bilinear=False):\n",
    "        super(UNet1, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv1(n_channels, 64)\n",
    "        self.down1 = Down1(64, 128)\n",
    "        self.down2 = Down1(128, 256)\n",
    "        self.down3 = Down1(256, 512)\n",
    "        self.down4 = Down1(512, 512)\n",
    "        self.up1 = Up1(1024, 256, bilinear)\n",
    "        self.up2 = Up1(512, 128, bilinear)\n",
    "        self.up3 = Up1(256, 64, bilinear)\n",
    "        self.up4 = Up1(128, 64, bilinear)\n",
    "        self.outc = OutConv1(64, 20)\n",
    "#         self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        out = logits.view(logits.size(0),-1)\n",
    "#         out = self.relu(logits)\n",
    "#         out = self.sigmoid(logits)\n",
    "        # result = torch.as_tensor((out - 0.5) > 0, dtype=torch.int64) \n",
    "        return out\n",
    "\n",
    "class DoubleConv2(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        channels = out_channels // 2\n",
    "        if in_channels > out_channels:\n",
    "            channels = in_channels // 2\n",
    "            \n",
    "        self.double_conv2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, channels, kernel_size=(3,3,3), padding=2),\n",
    "            nn.BatchNorm3d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(channels, out_channels, kernel_size=(3,3,3), padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv2(x)\n",
    "\n",
    "\n",
    "class Down2(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.2),\n",
    "            DoubleConv2(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up2(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up1 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up1 = nn.ConvTranspose3d(in_channels , in_channels // 2, kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        self.conv = DoubleConv2(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up1(x1)\n",
    "        # input is CHW\n",
    "        diffZ = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffY = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "        diffX = torch.tensor([x2.size()[4] - x1.size()[4]])\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2,\n",
    "                        diffZ // 2, diffZ - diffZ // 2])\n",
    "        # x1(256,512,5,4,4) x2(5,4,4)\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv2, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels , kernel_size=(5,5,5))\n",
    "        \n",
    "        # self.fc1 = nn.Linear(19200, 16000)\n",
    "    def forward(self, x):\n",
    "        # input_size = x.size(0)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class UNet2(nn.Module):   ### AMT channel\n",
    "    def __init__(self, n_channels = 2, n_classes = 20, bilinear=False):\n",
    "        super(UNet2, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv2(n_channels, 64)\n",
    "        self.down1 = Down2(64, 128)\n",
    "        self.down2 = Down2(128, 256)\n",
    "        self.down3 = Down2(256, 512)\n",
    "#         self.down4 = Down2(512, 512)\n",
    "        self.up1 = Up2(512, 256, bilinear=0)\n",
    "        self.up2 = Up2(256, 128, bilinear=0)\n",
    "        self.up3 = Up2(128, 64, bilinear=0)\n",
    "        self.outc = OutConv2(64, 20)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)       # x(2,5,8,10)  (64,7,10,12)\n",
    "        x2 = self.down1(x1)    #(128,5,7,8)\n",
    "        x3 = self.down2(x2)    #(256,4,5,6)\n",
    "        x4 = self.down3(x3)    #(512,4,4,5)\n",
    "#         x5 = self.down4(x4)    #(1028,4,4,4)\n",
    "        x = self.up1(x4, x3)   #(512,6,7,8)\n",
    "        x = self.up2(x, x2)    #(128,7,9,10)\n",
    "        x = self.up3(x, x1)    #(64,9,12,14)\n",
    "#         x = self.up4(x, x1)    #(64,14,9,12)\n",
    "        logits = self.outc(x)  #(256,20,5,8,10)\n",
    "        out = logits.view(logits.size(0),-1)   #(256,8000)\n",
    "        # out = self.sigmoid(logits)\n",
    "        # result = torch.as_tensor((out - 0.5) > 0, dtype=torch.int64) \n",
    "        return out\n",
    "\n",
    "\n",
    "class DoubleConv3(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=2),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down3(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.2),\n",
    "            DoubleConv3(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up3(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up3 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up3 = nn.ConvTranspose1d(in_channels // 2, in_channels // 2, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.conv = DoubleConv3(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up3(x1) #(256,11) #(256,8)\n",
    "\n",
    "        diff = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        x1 = F.pad(x1, [diff // 2, diff - diff // 2])\n",
    "        # diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        \n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv3(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv3, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels , kernel_size=5)\n",
    "        \n",
    "        # self.fc1 = nn.Linear(19200, 16000)\n",
    "    def forward(self, x):\n",
    "        # input_size = x.size(0)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class UNet3(nn.Module):\n",
    "    def __init__(self, n_channels = 2, n_classes = 400, bilinear=False):\n",
    "        super(UNet3, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv3(n_channels, 64)\n",
    "        self.down1 = Down3(64, 128)\n",
    "        self.down2 = Down3(128, 256)\n",
    "        self.down3 = Down3(256, 512)\n",
    "        self.down4 = Down3(512, 512)\n",
    "        self.up1 = Up3(1024, 256, bilinear=0)\n",
    "        self.up2 = Up3(512, 128, bilinear=0)\n",
    "        self.up3 = Up3(256, 64, bilinear=0)\n",
    "        self.up4 = Up3(128, 64, bilinear=0)\n",
    "        self.outc = OutConv3(64, n_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        out = logits.view(logits.size(0),-1)   #(256,8000)\n",
    "        # out = self.sigmoid(logits)\n",
    "        # result = torch.as_tensor((out - 0.5) > 0, dtype=torch.int64) \n",
    "        return out       \n",
    "\n",
    "    \n",
    "class Unet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet1, self).__init__()\n",
    "        self.unet0 = UNet0()\n",
    "        self.unet1 = UNet1()\n",
    "        self.unet2 = UNet2()\n",
    "        self.unet3 = UNet3()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "         \n",
    "    # def forward(self, x0, x1):\n",
    "    def forward(self, x0,x1,x2,x3):\n",
    "        y0 = self.unet0(x0)\n",
    "        y1 = self.unet1(x1)\n",
    "        y2 = self.unet2(x2)\n",
    "        y3 = self.unet3(x3)\n",
    "\n",
    "        out0 = self.sigmoid(y0)     #mag(256,8000)\n",
    "        out1 = self.sigmoid(y1)     #gra(256,8000)\n",
    "        out2 = self.sigmoid(y2)     #amt(256,8000)\n",
    "        out3 = self.sigmoid(y3)     #well(256,8000)\n",
    "        \n",
    "        result = 1/4*(out0+out1+out2+out3) #########(32,8000)\n",
    "#         out = result.view([32,20,20,20])   #(256,20,20,20)\n",
    "        # result = torch.as_tensor((out - 0.5) > 0, dtype=torch.int64)\n",
    "        return result\n",
    "       \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    net1 = Unet1()\n",
    "#     print(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10bf91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "def valid(model,device,loader):\n",
    "    model.eval()\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "#     criterion = nn.MSELoss()\n",
    "    correct = 0\n",
    "    total = len(loader.dataset)\n",
    "    for x,x1,x2,x3,y in loader:\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        x1 = x1.to(device)\n",
    "        x2 = x2.to(device)\n",
    "        x3 = x3.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(x,x1,x2,x3) \n",
    "            loss = criterion(pred,y)\n",
    "            print('test loss:',loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4662da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230307_13_50_03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# from earlyval import *\n",
    "from tensorboardX import SummaryWriter\n",
    "import datetime\n",
    "nowtime = datetime.datetime.now().strftime('%Y%m%d_%H_%M_%S')\n",
    "print(nowtime + '\\n')\n",
    "pwd = os.getcwd()+'/' + 'log/' + nowtime\n",
    "isExists = os.path.exists(pwd)\n",
    "if not isExists:\n",
    "    os.makedirs(pwd)\n",
    "writer = SummaryWriter(pwd)\n",
    "\n",
    "\n",
    "def train_net(net, device, dataloader1, dataloader3,dataloader5,epochs, batch_size, lr):\n",
    "    # 加载训练集\n",
    "   \n",
    "    # 定义RMSprop算法\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "#     optimizer = optim.Adam(net.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "#     optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum=0.9)\n",
    "    # 定义Loss算法\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "#     criterion = nn.MSELoss()\n",
    "    # best_loss统计，初始化为正无穷\n",
    "    best_loss = float('inf')\n",
    "    # 训练epochs次\n",
    "    for epoch in range(epochs):\n",
    "        # 训练模式\n",
    "        net.train()\n",
    "        # 按照batch_size开始训练\n",
    "#         for image, label in train_loader:\n",
    "        for (i, (image0,image1,image2,image3, label)) in enumerate(dataloader1):\n",
    "            optimizer.zero_grad()\n",
    "            # 将数据拷贝到device中\n",
    "            image0 = image0.to(device=device, dtype=torch.float32)\n",
    "            image1 = image1.to(device=device, dtype=torch.float32)\n",
    "            image2 = image2.to(device=device, dtype=torch.float32)\n",
    "            image3 = image3.to(device=device, dtype=torch.float32)\n",
    "            label = label.to(device=device, dtype=torch.float32)\n",
    "            # 使用网络参数，输出预测结果\n",
    "            pred0 = net(image0,image1,image2,image3)\n",
    "            # pred1 = net(image1)\n",
    "\n",
    "            result0 = torch.as_tensor((pred0 - 0.5) > 0, dtype=torch.int64) \n",
    "            # result1 = torch.as_tensor((pred1 - 0.5) > 0, dtype=torch.int64) \n",
    "#             result = pred0.detach().numpy()\n",
    "#             label_ = label.numpy()\n",
    "\n",
    "            loss0 = criterion(pred0, label)\n",
    "#             loss1 = criterion(pred1, label1)\n",
    "            loss = loss0\n",
    "            niter = epoch*len(dataloader1)+i\n",
    "            if niter % 2 == 0:\n",
    "                val_acc = valid(net,device,dataloader3)\n",
    "                # print('val acc :', val_acc)\n",
    "                \n",
    "                writer.add_scalar('Val loss',val_acc,niter)\n",
    "                writer.add_scalar('Train loss',loss,niter)\n",
    "                writer.add_graph(net,(image0,image1,image2,image3,))\n",
    "                writer.flush()\n",
    "                test_acc = valid(net,device,dataloader5)\n",
    "                writer.add_scalar('Test loss',test_acc,niter)\n",
    "                writer.flush()\n",
    "            print('Loss/train', loss.item())\n",
    "\n",
    "            # 保存loss值最小的网络参数\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                torch.save(net.state_dict(), 'best_model90.pth')\n",
    "            # 更新参数\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('epoch: {} '.format(epoch))\n",
    "    # print('val acc :', val_acc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd389e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd2d02d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet1(\n",
      "  (unet0): UNet0(\n",
      "    (inc): DoubleConv0(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(1, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (down1): Down0(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv0(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (down2): Down0(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv0(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (down3): Down0(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv0(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (down4): Down0(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv0(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up1): Up0(\n",
      "      (up): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "      (conv): DoubleConv0(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up2): Up0(\n",
      "      (up): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "      (conv): DoubleConv0(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up3): Up0(\n",
      "      (up): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "      (conv): DoubleConv0(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(256, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up4): Up0(\n",
      "      (up): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "      (conv): DoubleConv0(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(128, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (outc): OutConv0(\n",
      "      (conv): Conv2d(64, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (unet1): UNet1(\n",
      "    (inc): DoubleConv1(\n",
      "      (double_conv1): Sequential(\n",
      "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (down1): Down1(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv1(\n",
      "          (double_conv1): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (down2): Down1(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv1(\n",
      "          (double_conv1): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (down3): Down1(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv1(\n",
      "          (double_conv1): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (down4): Down1(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv1(\n",
      "          (double_conv1): Sequential(\n",
      "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up1): Up1(\n",
      "      (up): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv): DoubleConv1(\n",
      "        (double_conv1): Sequential(\n",
      "          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up2): Up1(\n",
      "      (up): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv): DoubleConv1(\n",
      "        (double_conv1): Sequential(\n",
      "          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up3): Up1(\n",
      "      (up): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv): DoubleConv1(\n",
      "        (double_conv1): Sequential(\n",
      "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up4): Up1(\n",
      "      (up): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv): DoubleConv1(\n",
      "        (double_conv1): Sequential(\n",
      "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (outc): OutConv1(\n",
      "      (conv): Conv2d(64, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "    )\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (unet2): UNet2(\n",
      "    (inc): DoubleConv2(\n",
      "      (double_conv2): Sequential(\n",
      "        (0): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (down1): Down2(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv2(\n",
      "          (double_conv2): Sequential(\n",
      "            (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "            (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (down2): Down2(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv2(\n",
      "          (double_conv2): Sequential(\n",
      "            (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "            (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (down3): Down2(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv2(\n",
      "          (double_conv2): Sequential(\n",
      "            (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "            (4): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up1): Up2(\n",
      "      (up1): ConvTranspose3d(512, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "      (conv): DoubleConv2(\n",
      "        (double_conv2): Sequential(\n",
      "          (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up2): Up2(\n",
      "      (up1): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "      (conv): DoubleConv2(\n",
      "        (double_conv2): Sequential(\n",
      "          (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up3): Up2(\n",
      "      (up1): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "      (conv): DoubleConv2(\n",
      "        (double_conv2): Sequential(\n",
      "          (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (outc): OutConv2(\n",
      "      (conv): Conv3d(64, 20, kernel_size=(5, 5, 5), stride=(1, 1, 1))\n",
      "    )\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (unet3): UNet3(\n",
      "    (inc): DoubleConv3(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv1d(2, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (down1): Down3(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv3(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "            (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (down2): Down3(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv3(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "            (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (down3): Down3(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv3(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "            (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (down4): Down3(\n",
      "      (maxpool_conv): Sequential(\n",
      "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (1): Dropout(p=0.2, inplace=False)\n",
      "        (2): DoubleConv3(\n",
      "          (double_conv): Sequential(\n",
      "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "            (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "            (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up1): Up3(\n",
      "      (up3): ConvTranspose1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (conv): DoubleConv3(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv1d(1024, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up2): Up3(\n",
      "      (up3): ConvTranspose1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (conv): DoubleConv3(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up3): Up3(\n",
      "      (up3): ConvTranspose1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (conv): DoubleConv3(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (up4): Up3(\n",
      "      (up3): ConvTranspose1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
      "      (conv): DoubleConv3(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,))\n",
      "          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (outc): OutConv3(\n",
      "      (conv): Conv1d(64, 400, kernel_size=(5,), stride=(1,))\n",
      "    )\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# name:weinanyu\n",
    "# date:20220316\n",
    "# early fusion\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "os.getcwd()\n",
    "os.chdir\n",
    "import numpy as np\n",
    "# import DataFunc\n",
    "\n",
    "# from model import *\n",
    "path_G = '/home/weinanyu/try/data23/new25/g.npy'\n",
    "path_M = '/home/weinanyu/try/data23/new25/m.npy'\n",
    "path_EM = '/home/weinanyu/try/data23/new25/EM2.npy'\n",
    "path_WELL = '/home/weinanyu/try/data23/new25/well.npy'\n",
    "# path_G = '/home/weinanyu/try/data3/alldata_g.npy'\n",
    "# path_M = '/home/weinanyu/try/data3/alldata_m.npy'\n",
    "path_Y = '/home/weinanyu/try/data23/new25/y.npy'\n",
    "# path_G = '/home/weinanyu/try/data18/new1/g.npy'\n",
    "# path_M = '/home/weinanyu/try/data18/new1/m.npy'\n",
    "# path_EM = '/home/weinanyu/try/data18/new1/EM2.npy'\n",
    "# path_WELL = '/home/weinanyu/try/data18/new1/well.npy'\n",
    "# # # path_G = '/home/weinanyu/try/data3/alldata_g.npy'\n",
    "# # # path_M = '/home/weinanyu/try/data3/alldata_m.npy'\n",
    "# path_Y = '/home/weinanyu/try/data18/new1/y.npy'\n",
    "\n",
    "\n",
    "\n",
    "# test_g = '/home/weinanyu/try/data23/new25/g.npy'\n",
    "# test_m = '/home/weinanyu/try/data23/new25/m.npy'\n",
    "# test_em = '/home/weinanyu/try/data23/new25/EM2.npy'\n",
    "# test_well = '/home/weinanyu/try/data23/new25/well.npy'\n",
    "# test_y = '/home/weinanyu/try/data23/new25/y.npy'\n",
    "# test_g='/home/weinanyu/try/data21_test/new/g.npy'\n",
    "# test_m='/home/weinanyu/try/data21_test/new/m.npy'\n",
    "# test_em='/home/weinanyu/try/data21_test/new/EM2.npy'\n",
    "# test_well='/home/weinanyu/try/data21_test/new/well.npy'\n",
    "# test_y = '/home/weinanyu/try/data21_test/y.npy'\n",
    "test_g='/home/weinanyu/try/data_test141/g.npy'\n",
    "test_m='/home/weinanyu/try/data_test141/m.npy'\n",
    "test_em='/home/weinanyu/try/data_test141/EM2.npy'\n",
    "test_well='/home/weinanyu/try/data_test141/well.npy'\n",
    "test_y = '/home/weinanyu/try/data_test141/y.npy'\n",
    "dataset = loaddata_func(path_G,path_M,path_EM,path_WELL,path_Y,number =200)\n",
    "train_set,valid_set = shuffle_func(dataset,shuffle_ratio = 0.9)\n",
    "test_set = test_func(test_g,test_m,test_em,test_well,test_y,number = 1)\n",
    "# test_set = test_func(path_G,path_M,path_EM,path_WELL,path_Y,number =7)\n",
    "# %%\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 32\n",
    "dataloader1 = DataLoader(train_set, batch_size,shuffle=True) # 训练集\n",
    "dataloader3 = DataLoader(valid_set, batch_size,shuffle=True) # 验证集\n",
    "dataloader5 = DataLoader(test_set, batch_size,shuffle=True) # 测试集\n",
    "# %%\n",
    "\n",
    "net =  Unet1()\n",
    "print(net)\n",
    "# %%\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 选择设备，有cuda用cuda，没有就用cpu\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     net.load_state_dict(torch.load('best_model77.pth'))\n",
    "#     device = torch.device('cpu')\n",
    "    net.to(device=device)\n",
    "    \n",
    "#     train_net(net, device, dataloader1, dataloader3,dataloader3,epochs=1500, batch_size = 128, lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da3563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cdec4cd",
   "metadata": {},
   "source": [
    "## OUT OF MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab0cb03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pkill -u weinanyu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d24a1c7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet1(\n",
       "  (unet0): UNet0(\n",
       "    (inc): DoubleConv0(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down1): Down0(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv0(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down2): Down0(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv0(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down3): Down0(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv0(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down4): Down0(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv0(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up1): Up0(\n",
       "      (up): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "      (conv): DoubleConv0(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up2): Up0(\n",
       "      (up): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "      (conv): DoubleConv0(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 128, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up3): Up0(\n",
       "      (up): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "      (conv): DoubleConv0(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up4): Up0(\n",
       "      (up): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "      (conv): DoubleConv0(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (outc): OutConv0(\n",
       "      (conv): Conv2d(64, 20, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (unet1): UNet1(\n",
       "    (inc): DoubleConv1(\n",
       "      (double_conv1): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down1): Down1(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv1(\n",
       "          (double_conv1): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down2): Down1(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv1(\n",
       "          (double_conv1): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down3): Down1(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv1(\n",
       "          (double_conv1): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down4): Down1(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv1(\n",
       "          (double_conv1): Sequential(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up1): Up1(\n",
       "      (up): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv): DoubleConv1(\n",
       "        (double_conv1): Sequential(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up2): Up1(\n",
       "      (up): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv): DoubleConv1(\n",
       "        (double_conv1): Sequential(\n",
       "          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up3): Up1(\n",
       "      (up): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv): DoubleConv1(\n",
       "        (double_conv1): Sequential(\n",
       "          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up4): Up1(\n",
       "      (up): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv): DoubleConv1(\n",
       "        (double_conv1): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (outc): OutConv1(\n",
       "      (conv): Conv2d(64, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (unet2): UNet2(\n",
       "    (inc): DoubleConv2(\n",
       "      (double_conv2): Sequential(\n",
       "        (0): Conv3d(2, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "        (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "        (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down1): Down2(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv2(\n",
       "          (double_conv2): Sequential(\n",
       "            (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "            (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "            (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down2): Down2(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv2(\n",
       "          (double_conv2): Sequential(\n",
       "            (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "            (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "            (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down3): Down2(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv2(\n",
       "          (double_conv2): Sequential(\n",
       "            (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "            (4): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up1): Up2(\n",
       "      (up1): ConvTranspose3d(512, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (conv): DoubleConv2(\n",
       "        (double_conv2): Sequential(\n",
       "          (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up2): Up2(\n",
       "      (up1): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (conv): DoubleConv2(\n",
       "        (double_conv2): Sequential(\n",
       "          (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up3): Up2(\n",
       "      (up1): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (conv): DoubleConv2(\n",
       "        (double_conv2): Sequential(\n",
       "          (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (outc): OutConv2(\n",
       "      (conv): Conv3d(64, 20, kernel_size=(5, 5, 5), stride=(1, 1, 1))\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (unet3): UNet3(\n",
       "    (inc): DoubleConv3(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv1d(2, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (down1): Down3(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv3(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "            (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down2): Down3(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv3(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "            (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down3): Down3(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv3(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "            (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (down4): Down3(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): Dropout(p=0.2, inplace=False)\n",
       "        (2): DoubleConv3(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "            (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up1): Up3(\n",
       "      (up3): ConvTranspose1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (conv): DoubleConv3(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv1d(1024, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "          (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up2): Up3(\n",
       "      (up3): ConvTranspose1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (conv): DoubleConv3(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "          (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up3): Up3(\n",
       "      (up3): ConvTranspose1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (conv): DoubleConv3(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up4): Up3(\n",
       "      (up3): ConvTranspose1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (conv): DoubleConv3(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,))\n",
       "          (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (outc): OutConv3(\n",
       "      (conv): Conv1d(64, 400, kernel_size=(5,), stride=(1,))\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('best_model84.pth'))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "net.to(device=device)\n",
    "# train_net(net, device, dataloader1, dataloader3,dataloader3,epochs=400, batch_size = 256, lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "097d8baf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40429043]\n",
      "(1, 20, 20, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_260695/4251269023.py:58: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
      "/tmp/ipykernel_260695/4251269023.py:59: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  diffY // 2, diffY - diffY // 2])\n",
      "/tmp/ipykernel_260695/4251269023.py:176: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
      "/tmp/ipykernel_260695/4251269023.py:177: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  diffY // 2, diffY - diffY // 2])\n",
      "/tmp/ipykernel_260695/4251269023.py:299: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
      "/tmp/ipykernel_260695/4251269023.py:300: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  diffY // 2, diffY - diffY // 2,\n",
      "/tmp/ipykernel_260695/4251269023.py:301: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  diffZ // 2, diffZ - diffZ // 2])\n",
      "/tmp/ipykernel_260695/4251269023.py:407: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x1 = F.pad(x1, [diff // 2, diff - diff // 2])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "/* global mpl */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function () {\n",
       "    if (typeof WebSocket !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof MozWebSocket !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert(\n",
       "            'Your browser does not have WebSocket support. ' +\n",
       "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "                'Firefox 4 and 5 are also supported but you ' +\n",
       "                'have to enable WebSockets in about:config.'\n",
       "        );\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = this.ws.binaryType !== undefined;\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById('mpl-warnings');\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent =\n",
       "                'This browser does not support binary websocket messages. ' +\n",
       "                'Performance may be slow.';\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = document.createElement('div');\n",
       "    this.root.setAttribute('style', 'display: inline-block');\n",
       "    this._root_extra_style(this.root);\n",
       "\n",
       "    parent_element.appendChild(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen = function () {\n",
       "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
       "        fig.send_message('send_image_mode', {});\n",
       "        if (fig.ratio !== 1) {\n",
       "            fig.send_message('set_device_pixel_ratio', {\n",
       "                device_pixel_ratio: fig.ratio,\n",
       "            });\n",
       "        }\n",
       "        fig.send_message('refresh', {});\n",
       "    };\n",
       "\n",
       "    this.imageObj.onload = function () {\n",
       "        if (fig.image_mode === 'full') {\n",
       "            // Full images could contain transparency (where diff images\n",
       "            // almost always do), so we need to clear the canvas so that\n",
       "            // there is no ghosting.\n",
       "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "        }\n",
       "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "    };\n",
       "\n",
       "    this.imageObj.onunload = function () {\n",
       "        fig.ws.close();\n",
       "    };\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_header = function () {\n",
       "    var titlebar = document.createElement('div');\n",
       "    titlebar.classList =\n",
       "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
       "    var titletext = document.createElement('div');\n",
       "    titletext.classList = 'ui-dialog-title';\n",
       "    titletext.setAttribute(\n",
       "        'style',\n",
       "        'width: 100%; text-align: center; padding: 3px;'\n",
       "    );\n",
       "    titlebar.appendChild(titletext);\n",
       "    this.root.appendChild(titlebar);\n",
       "    this.header = titletext;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
       "    canvas_div.setAttribute(\n",
       "        'style',\n",
       "        'border: 1px solid #ddd;' +\n",
       "            'box-sizing: content-box;' +\n",
       "            'clear: both;' +\n",
       "            'min-height: 1px;' +\n",
       "            'min-width: 1px;' +\n",
       "            'outline: 0;' +\n",
       "            'overflow: hidden;' +\n",
       "            'position: relative;' +\n",
       "            'resize: both;'\n",
       "    );\n",
       "\n",
       "    function on_keyboard_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.key_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    canvas_div.addEventListener(\n",
       "        'keydown',\n",
       "        on_keyboard_event_closure('key_press')\n",
       "    );\n",
       "    canvas_div.addEventListener(\n",
       "        'keyup',\n",
       "        on_keyboard_event_closure('key_release')\n",
       "    );\n",
       "\n",
       "    this._canvas_extra_style(canvas_div);\n",
       "    this.root.appendChild(canvas_div);\n",
       "\n",
       "    var canvas = (this.canvas = document.createElement('canvas'));\n",
       "    canvas.classList.add('mpl-canvas');\n",
       "    canvas.setAttribute('style', 'box-sizing: content-box;');\n",
       "\n",
       "    this.context = canvas.getContext('2d');\n",
       "\n",
       "    var backingStore =\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        this.context.webkitBackingStorePixelRatio ||\n",
       "        this.context.mozBackingStorePixelRatio ||\n",
       "        this.context.msBackingStorePixelRatio ||\n",
       "        this.context.oBackingStorePixelRatio ||\n",
       "        this.context.backingStorePixelRatio ||\n",
       "        1;\n",
       "\n",
       "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
       "        'canvas'\n",
       "    ));\n",
       "    rubberband_canvas.setAttribute(\n",
       "        'style',\n",
       "        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n",
       "    );\n",
       "\n",
       "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
       "    if (this.ResizeObserver === undefined) {\n",
       "        if (window.ResizeObserver !== undefined) {\n",
       "            this.ResizeObserver = window.ResizeObserver;\n",
       "        } else {\n",
       "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
       "            this.ResizeObserver = obs.ResizeObserver;\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
       "        var nentries = entries.length;\n",
       "        for (var i = 0; i < nentries; i++) {\n",
       "            var entry = entries[i];\n",
       "            var width, height;\n",
       "            if (entry.contentBoxSize) {\n",
       "                if (entry.contentBoxSize instanceof Array) {\n",
       "                    // Chrome 84 implements new version of spec.\n",
       "                    width = entry.contentBoxSize[0].inlineSize;\n",
       "                    height = entry.contentBoxSize[0].blockSize;\n",
       "                } else {\n",
       "                    // Firefox implements old version of spec.\n",
       "                    width = entry.contentBoxSize.inlineSize;\n",
       "                    height = entry.contentBoxSize.blockSize;\n",
       "                }\n",
       "            } else {\n",
       "                // Chrome <84 implements even older version of spec.\n",
       "                width = entry.contentRect.width;\n",
       "                height = entry.contentRect.height;\n",
       "            }\n",
       "\n",
       "            // Keep the size of the canvas and rubber band canvas in sync with\n",
       "            // the canvas container.\n",
       "            if (entry.devicePixelContentBoxSize) {\n",
       "                // Chrome 84 implements new version of spec.\n",
       "                canvas.setAttribute(\n",
       "                    'width',\n",
       "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
       "                );\n",
       "                canvas.setAttribute(\n",
       "                    'height',\n",
       "                    entry.devicePixelContentBoxSize[0].blockSize\n",
       "                );\n",
       "            } else {\n",
       "                canvas.setAttribute('width', width * fig.ratio);\n",
       "                canvas.setAttribute('height', height * fig.ratio);\n",
       "            }\n",
       "            canvas.setAttribute(\n",
       "                'style',\n",
       "                'width: ' + width + 'px; height: ' + height + 'px;'\n",
       "            );\n",
       "\n",
       "            rubberband_canvas.setAttribute('width', width);\n",
       "            rubberband_canvas.setAttribute('height', height);\n",
       "\n",
       "            // And update the size in Python. We ignore the initial 0/0 size\n",
       "            // that occurs as the element is placed into the DOM, which should\n",
       "            // otherwise not happen due to the minimum size styling.\n",
       "            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n",
       "                fig.request_resize(width, height);\n",
       "            }\n",
       "        }\n",
       "    });\n",
       "    this.resizeObserverInstance.observe(canvas_div);\n",
       "\n",
       "    function on_mouse_event_closure(name) {\n",
       "        return function (event) {\n",
       "            return fig.mouse_event(event, name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousedown',\n",
       "        on_mouse_event_closure('button_press')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseup',\n",
       "        on_mouse_event_closure('button_release')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'dblclick',\n",
       "        on_mouse_event_closure('dblclick')\n",
       "    );\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mousemove',\n",
       "        on_mouse_event_closure('motion_notify')\n",
       "    );\n",
       "\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseenter',\n",
       "        on_mouse_event_closure('figure_enter')\n",
       "    );\n",
       "    rubberband_canvas.addEventListener(\n",
       "        'mouseleave',\n",
       "        on_mouse_event_closure('figure_leave')\n",
       "    );\n",
       "\n",
       "    canvas_div.addEventListener('wheel', function (event) {\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        on_mouse_event_closure('scroll')(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.appendChild(canvas);\n",
       "    canvas_div.appendChild(rubberband_canvas);\n",
       "\n",
       "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
       "    this.rubberband_context.strokeStyle = '#000000';\n",
       "\n",
       "    this._resize_canvas = function (width, height, forward) {\n",
       "        if (forward) {\n",
       "            canvas_div.style.width = width + 'px';\n",
       "            canvas_div.style.height = height + 'px';\n",
       "        }\n",
       "    };\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n",
       "        event.preventDefault();\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus() {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'mpl-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'mpl-button-group';\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'mpl-button-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        var button = (fig.buttons[name] = document.createElement('button'));\n",
       "        button.classList = 'mpl-widget';\n",
       "        button.setAttribute('role', 'button');\n",
       "        button.setAttribute('aria-disabled', 'false');\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "\n",
       "        var icon_img = document.createElement('img');\n",
       "        icon_img.src = '_images/' + image + '.png';\n",
       "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
       "        icon_img.alt = tooltip;\n",
       "        button.appendChild(icon_img);\n",
       "\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    var fmt_picker = document.createElement('select');\n",
       "    fmt_picker.classList = 'mpl-widget';\n",
       "    toolbar.appendChild(fmt_picker);\n",
       "    this.format_dropdown = fmt_picker;\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = document.createElement('option');\n",
       "        option.selected = fmt === mpl.default_extension;\n",
       "        option.innerHTML = fmt;\n",
       "        fmt_picker.appendChild(option);\n",
       "    }\n",
       "\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_message = function (type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function () {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
       "        fig.send_message('refresh', {});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
       "    var x0 = msg['x0'] / fig.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
       "    var x1 = msg['x1'] / fig.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0,\n",
       "        0,\n",
       "        fig.canvas.width / fig.ratio,\n",
       "        fig.canvas.height / fig.ratio\n",
       "    );\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
       "    fig.rubberband_canvas.style.cursor = msg['cursor'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
       "    for (var key in msg) {\n",
       "        if (!(key in fig.buttons)) {\n",
       "            continue;\n",
       "        }\n",
       "        fig.buttons[key].disabled = !msg[key];\n",
       "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
       "    if (msg['mode'] === 'PAN') {\n",
       "        fig.buttons['Pan'].classList.add('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    } else if (msg['mode'] === 'ZOOM') {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.add('active');\n",
       "    } else {\n",
       "        fig.buttons['Pan'].classList.remove('active');\n",
       "        fig.buttons['Zoom'].classList.remove('active');\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message('ack', {});\n",
       "};\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            var img = evt.data;\n",
       "            if (img.type !== 'image/png') {\n",
       "                /* FIXME: We get \"Resource interpreted as Image but\n",
       "                 * transferred with MIME type text/plain:\" errors on\n",
       "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "                 * to be part of the websocket stream */\n",
       "                img.type = 'image/png';\n",
       "            }\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src\n",
       "                );\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                img\n",
       "            );\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        } else if (\n",
       "            typeof evt.data === 'string' &&\n",
       "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
       "        ) {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig['handle_' + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\n",
       "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
       "                msg\n",
       "            );\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\n",
       "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
       "                    e,\n",
       "                    e.stack,\n",
       "                    msg\n",
       "                );\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "};\n",
       "\n",
       "// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function (e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e) {\n",
       "        e = window.event;\n",
       "    }\n",
       "    if (e.target) {\n",
       "        targ = e.target;\n",
       "    } else if (e.srcElement) {\n",
       "        targ = e.srcElement;\n",
       "    }\n",
       "    if (targ.nodeType === 3) {\n",
       "        // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "    }\n",
       "\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    var boundingRect = targ.getBoundingClientRect();\n",
       "    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n",
       "    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n",
       "\n",
       "    return { x: x, y: y };\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * https://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys(original) {\n",
       "    return Object.keys(original).reduce(function (obj, key) {\n",
       "        if (typeof original[key] !== 'object') {\n",
       "            obj[key] = original[key];\n",
       "        }\n",
       "        return obj;\n",
       "    }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function (event, name) {\n",
       "    var canvas_pos = mpl.findpos(event);\n",
       "\n",
       "    if (name === 'button_press') {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * this.ratio;\n",
       "    var y = canvas_pos.y * this.ratio;\n",
       "\n",
       "    this.send_message(name, {\n",
       "        x: x,\n",
       "        y: y,\n",
       "        button: event.button,\n",
       "        step: event.step,\n",
       "        guiEvent: simpleKeys(event),\n",
       "    });\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.key_event = function (event, name) {\n",
       "    // Prevent repeat events\n",
       "    if (name === 'key_press') {\n",
       "        if (event.key === this._key) {\n",
       "            return;\n",
       "        } else {\n",
       "            this._key = event.key;\n",
       "        }\n",
       "    }\n",
       "    if (name === 'key_release') {\n",
       "        this._key = null;\n",
       "    }\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.key !== 'Control') {\n",
       "        value += 'ctrl+';\n",
       "    }\n",
       "    else if (event.altKey && event.key !== 'Alt') {\n",
       "        value += 'alt+';\n",
       "    }\n",
       "    else if (event.shiftKey && event.key !== 'Shift') {\n",
       "        value += 'shift+';\n",
       "    }\n",
       "\n",
       "    value += 'k' + event.key;\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
       "    return false;\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
       "    if (name === 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message('toolbar_button', { name: name });\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "\n",
       "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
       "// prettier-ignore\n",
       "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";/* global mpl */\n",
       "\n",
       "var comm_websocket_adapter = function (comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.binaryType = comm.kernel.ws.binaryType;\n",
       "    ws.readyState = comm.kernel.ws.readyState;\n",
       "    function updateReadyState(_event) {\n",
       "        if (comm.kernel.ws) {\n",
       "            ws.readyState = comm.kernel.ws.readyState;\n",
       "        } else {\n",
       "            ws.readyState = 3; // Closed state.\n",
       "        }\n",
       "    }\n",
       "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
       "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
       "\n",
       "    ws.close = function () {\n",
       "        comm.close();\n",
       "    };\n",
       "    ws.send = function (m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function (msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        var data = msg['content']['data'];\n",
       "        if (data['blob'] !== undefined) {\n",
       "            data = {\n",
       "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
       "            };\n",
       "        }\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(data);\n",
       "    });\n",
       "    return ws;\n",
       "};\n",
       "\n",
       "mpl.mpl_figure_comm = function (comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = document.getElementById(id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm);\n",
       "\n",
       "    function ondownload(figure, _format) {\n",
       "        window.open(figure.canvas.toDataURL());\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element;\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error('Failed to find cell for figure', id, fig);\n",
       "        return;\n",
       "    }\n",
       "    fig.cell_info[0].output_area.element.on(\n",
       "        'cleared',\n",
       "        { fig: fig },\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
       "    var width = fig.canvas.width / fig.ratio;\n",
       "    fig.cell_info[0].output_area.element.off(\n",
       "        'cleared',\n",
       "        fig._remove_fig_handler\n",
       "    );\n",
       "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable();\n",
       "    fig.parent_element.innerHTML =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "    fig.close_ws(fig, msg);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width / this.ratio;\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] =\n",
       "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function () {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message('ack', {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () {\n",
       "        fig.push_to_output();\n",
       "    }, 1000);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function () {\n",
       "    var fig = this;\n",
       "\n",
       "    var toolbar = document.createElement('div');\n",
       "    toolbar.classList = 'btn-toolbar';\n",
       "    this.root.appendChild(toolbar);\n",
       "\n",
       "    function on_click_closure(name) {\n",
       "        return function (_event) {\n",
       "            return fig.toolbar_button_onclick(name);\n",
       "        };\n",
       "    }\n",
       "\n",
       "    function on_mouseover_closure(tooltip) {\n",
       "        return function (event) {\n",
       "            if (!event.currentTarget.disabled) {\n",
       "                return fig.toolbar_button_onmouseover(tooltip);\n",
       "            }\n",
       "        };\n",
       "    }\n",
       "\n",
       "    fig.buttons = {};\n",
       "    var buttonGroup = document.createElement('div');\n",
       "    buttonGroup.classList = 'btn-group';\n",
       "    var button;\n",
       "    for (var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            /* Instead of a spacer, we start a new button group. */\n",
       "            if (buttonGroup.hasChildNodes()) {\n",
       "                toolbar.appendChild(buttonGroup);\n",
       "            }\n",
       "            buttonGroup = document.createElement('div');\n",
       "            buttonGroup.classList = 'btn-group';\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        button = fig.buttons[name] = document.createElement('button');\n",
       "        button.classList = 'btn btn-default';\n",
       "        button.href = '#';\n",
       "        button.title = name;\n",
       "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
       "        button.addEventListener('click', on_click_closure(method_name));\n",
       "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
       "        buttonGroup.appendChild(button);\n",
       "    }\n",
       "\n",
       "    if (buttonGroup.hasChildNodes()) {\n",
       "        toolbar.appendChild(buttonGroup);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = document.createElement('span');\n",
       "    status_bar.classList = 'mpl-message pull-right';\n",
       "    toolbar.appendChild(status_bar);\n",
       "    this.message = status_bar;\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = document.createElement('div');\n",
       "    buttongrp.classList = 'btn-group inline pull-right';\n",
       "    button = document.createElement('button');\n",
       "    button.classList = 'btn btn-mini btn-primary';\n",
       "    button.href = '#';\n",
       "    button.title = 'Stop Interaction';\n",
       "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
       "    button.addEventListener('click', function (_evt) {\n",
       "        fig.handle_close(fig, {});\n",
       "    });\n",
       "    button.addEventListener(\n",
       "        'mouseover',\n",
       "        on_mouseover_closure('Stop Interaction')\n",
       "    );\n",
       "    buttongrp.appendChild(button);\n",
       "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
       "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
       "    var fig = event.data.fig;\n",
       "    if (event.target !== this) {\n",
       "        // Ignore bubbled events from children.\n",
       "        return;\n",
       "    }\n",
       "    fig.close_ws(fig, {});\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function (el) {\n",
       "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
       "    // this is important to make the div 'focusable\n",
       "    el.setAttribute('tabindex', 0);\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    } else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which === 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "};\n",
       "\n",
       "mpl.find_output_cell = function (html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i = 0; i < ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code') {\n",
       "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] === html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel !== null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target(\n",
       "        'matplotlib',\n",
       "        mpl.mpl_figure_comm\n",
       "    );\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0,  ..., 0, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.0101e-05, 4.2223e-07, 1.4186e-07,  ..., 5.0057e-08, 7.1055e-07,\n",
       "         4.6061e-05]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "def plotpre(model,loader):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    correct = 0\n",
    "    total = len(loader.dataset)\n",
    "    for x,x1,x2,x3,y in loader:\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        x1 = x1.to(device)\n",
    "        x2 = x2.to(device)\n",
    "        x3 = x3.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(x,x1,x2,x3) \n",
    "        pred0 = torch.as_tensor((pred - 0.15) > 0, dtype=torch.int64) \n",
    "        pred1 = pred.detach().numpy()\n",
    "        pred00 = pred0.detach().numpy()\n",
    "        \n",
    "        y1 = y.numpy()\n",
    "#         print(pred1.size)\n",
    "        acc = iou(pred0, y)\n",
    "        print(acc)\n",
    "        pred01 = pred00.reshape(1,20,20,20)\n",
    "        pred2 = pred1.reshape(1,20,20,20)\n",
    "        y2 = y1.reshape(1,20,20,20)\n",
    "        print(y2.shape)\n",
    "        fig = plt.figure()\n",
    "        \n",
    "        ax1 = plt.subplot(3,3,1)   \n",
    "        h1 = plt.imshow(np.transpose(y2[0,9,:,:]))\n",
    "        c1 = plt.colorbar(h1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        \n",
    "        ax2 = plt.subplot(3,3,2) \n",
    "        h2 = plt.imshow(np.transpose(pred2[0,9,:,:]))\n",
    "        plt.colorbar(h2)\n",
    "        \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.show()\n",
    "        \n",
    "        ax3 = plt.subplot(3,3,3) \n",
    "        h22 = plt.imshow(np.transpose(pred01[0,9,:,:]))\n",
    "        plt.colorbar(h22)\n",
    "        plt.show()\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ax4 = plt.subplot(3,3,4)   \n",
    "        h3 = plt.imshow(np.transpose(y2[0,:,9,:]))\n",
    "        c3 = plt.colorbar(h3)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "\n",
    "        \n",
    "        ax5 = plt.subplot(3,3,5) \n",
    "        h4 = plt.imshow(np.transpose(pred2[0,:,9,:]))\n",
    "        plt.colorbar(h4)\n",
    "        plt.show()\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        ax6 = plt.subplot(3,3,6) \n",
    "        h44 = plt.imshow(np.transpose(pred01[0,:,9,:]))\n",
    "        plt.colorbar(h44)\n",
    "        plt.show()\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        \n",
    "        ax7 = plt.subplot(3,3,7)   \n",
    "        h5 = plt.imshow(y2[0,:,:,9])\n",
    "        c5 = plt.colorbar(h5)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        \n",
    "        ax8 = plt.subplot(3,3,8) \n",
    "        h6 = plt.imshow(pred2[0,:,:,9])\n",
    "        plt.colorbar(h6)\n",
    "        plt.show()\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        ax9 = plt.subplot(3,3,9) \n",
    "        h66 = plt.imshow(pred01[0,:,:,9])\n",
    "\n",
    "        plt.colorbar(h66)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "       \n",
    "        \n",
    "        plt.show()\n",
    "        print(pred0)\n",
    "        np.savetxt('/home/weinanyu/try/data25/si.txt',pred0)\n",
    "\n",
    "        \n",
    "    return pred\n",
    "# plotpre(model,dataloader3)\n",
    "plotpre(net,dataloader5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfa58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.savefig(\"/home/weinanyu/try/new/fig/6.png\") \n",
    "  \n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "62c79020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256.0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.spatial as spt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c48ce3",
   "metadata": {},
   "source": [
    "## TEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6fa8de13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 10])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,20,10)\n",
    "# np.shape(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "968718f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66278/1224142143.py:58: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
      "/tmp/ipykernel_66278/1224142143.py:59: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  diffY // 2, diffY - diffY // 2])\n",
      "/tmp/ipykernel_66278/1224142143.py:176: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
      "/tmp/ipykernel_66278/1224142143.py:177: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  diffY // 2, diffY - diffY // 2])\n",
      "/tmp/ipykernel_66278/1224142143.py:299: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
      "/tmp/ipykernel_66278/1224142143.py:300: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  diffY // 2, diffY - diffY // 2,\n",
      "/tmp/ipykernel_66278/1224142143.py:301: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  diffZ // 2, diffZ - diffZ // 2])\n",
      "/tmp/ipykernel_66278/1224142143.py:407: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x1 = F.pad(x1, [diff // 2, diff - diff // 2])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2048000 into shape (128,20,20,20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_66278/1839507371.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m# plotpre(model,dataloader3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mplotpre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloader1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_66278/1839507371.py\u001b[0m in \u001b[0;36mplotpre\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#         print(pred1.size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mpred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2048000 into shape (128,20,20,20)"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "def plotpre(model,loader):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    correct = 0\n",
    "    total = len(loader.dataset)\n",
    "    for x,x1,x2,x3,y in loader:\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        x1 = x1.to(device)\n",
    "        x2 = x2.to(device)\n",
    "        x3 = x3.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(x,x1,x2,x3) \n",
    "#         pred = torch.as_tensor((pred - 0.1) > 0, dtype=torch.int64) \n",
    "        \n",
    "        pred1 = pred.detach().numpy()\n",
    "        \n",
    "        y1 = y.numpy()\n",
    "        \n",
    "#         print(pred1.size)\n",
    "        pred2 = pred1.reshape(128,20,20,20)\n",
    "        y2 = y1.reshape(128,20,20,20)\n",
    "        \n",
    "#         if os.path.exists('/'+'model'):\n",
    "#             shutil.rmtree('/'+'model')\n",
    "#         os.mkdir('/'+'Pred')\n",
    "#         pred3=pred2[13,:,:,:]\n",
    "#         pred3 = pred3.reshape(8000,1)\n",
    "#         y3 = y2[13,:,:,:]\n",
    "#         y3 = y3.reshape(8000,1)\n",
    "#         os.chdir('/home/weinanyu/try/new/'+'Pred')\n",
    "#         np.savetxt('pred2.txt',pred3,fmt = '%.1f')\n",
    "#         np.savetxt('y2.txt',y3,fmt = '%.1f')\n",
    "        print(y2.shape)\n",
    "        fig = plt.figure()\n",
    "        ax1 = plt.subplot(3,2,1)   \n",
    "        h11 = pred2[13,8,:,:]\n",
    "        h1 = plt.imshow(np.transpose(h11))\n",
    "\n",
    "        c1 = plt.colorbar(h1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.axis('off')\n",
    "\n",
    "        \n",
    "        ax2 = plt.subplot(3,2,2) \n",
    "        h21 = y2[13,8,:,:]\n",
    "        h2 = plt.imshow(np.transpose(h21))\n",
    "\n",
    "#         h2 = plt.imshow(y2[13,10,:,:])\n",
    "        plt.colorbar(h2)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "#         c2 = plt.colorbar(h2)\n",
    "        \n",
    "        ax3 = plt.subplot(3,2,3) \n",
    "        h31 = pred2[13,:,10,:]\n",
    "        h3 = plt.imshow(h31)\n",
    "#         h3 = plt.imshow(pred2[13,:,8,:])\n",
    "        c3 = plt.colorbar(h3)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.axis('off')\n",
    "\n",
    "        \n",
    "        ax4 = plt.subplot(3,2,4) \n",
    "        h41 = y2[13,:,10,:]\n",
    "        h4 = plt.imshow(h41)\n",
    "#         h4 = plt.imshow(y2[13,:,8,:])\n",
    "        plt.colorbar(h4)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        ax5 = plt.subplot(3,2,5)   \n",
    "        h5 = plt.imshow(pred2[13,:,:,8])\n",
    "        c5 = plt.colorbar(h5)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.axis('off')\n",
    "\n",
    "        \n",
    "        ax6 = plt.subplot(3,2,6) \n",
    "        h6 = plt.imshow(y2[13,:,:,8])\n",
    "        plt.colorbar(h6)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.axis('off')\n",
    "        pred = torch.as_tensor((pred - 0.1) > 0, dtype=torch.int64) \n",
    "        acc = iou(pred, y)\n",
    "#         acc = iou(pred, y)\n",
    "        print(acc)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    return pred\n",
    "# plotpre(model,dataloader3)\n",
    "plotpre(net,dataloader1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842bdac6",
   "metadata": {},
   "source": [
    "## iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a424272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(pred, target, n_classes = 2):\n",
    "#n_classes ：the number of classes in your dataset\n",
    "    ious = []\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "\n",
    "    # Ignore IoU for background class (\"0\")\n",
    "    for cls in range(1, n_classes):  # This goes from 1:n_classes-1 -> class \"0\" is ignored\n",
    "        pred_inds = pred == cls\n",
    "        target_inds = target == cls\n",
    "        intersection = (pred_inds[target_inds]).long().sum().item()  # Cast to long to prevent overflows\n",
    "        union = pred_inds.long().sum().item() + target_inds.long().sum().item() - intersection\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # If there is no ground truth, do not include in evaluation\n",
    "        else:\n",
    "            ious.append(float(intersection) / float(max(union, 1)))\n",
    "        return np.array(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e2c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62a788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
